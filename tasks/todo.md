# LEGALS Project Setup Plan

## Project Overview
This is a Legal Empowerment and Awareness System that maps natural language descriptions to relevant Indian laws (BNS) using Neo4j graph database and Phi-3-mini AI model.

## Setup Tasks

### 1. Python Environment Setup
- [ ] Create Python virtual environment (Python 3.11+ required)
- [ ] Activate virtual environment
- [ ] Install Python dependencies from requirements.txt

### 2. Database Configuration

#### PostgreSQL Setup
- [ ] Install PostgreSQL (if not already installed)
- [ ] Create database named 'legals_db'
- [ ] Note down database credentials

#### Neo4j Setup
- [ ] Start Neo4j Desktop/Service
- [ ] Set Neo4j password (currently defaults to 'Avirup@190204' in config.py)
- [ ] Verify Neo4j is accessible at bolt://localhost:7687
- [ ] Import BNS legal knowledge graph data (if import scripts available)

### 3. Backend Environment Configuration
- [ ] Create .env file in backend/ directory based on .env.example
- [ ] Configure database credentials:
  - POSTGRES_SERVER=localhost
  - POSTGRES_USER=postgres
  - POSTGRES_PASSWORD=<your_password>
  - POSTGRES_DB=legals_db
- [ ] Configure Neo4j credentials:
  - NEO4J_URI=bolt://localhost:7687
  - NEO4J_USER=neo4j
  - NEO4J_PASSWORD=<your_neo4j_password>
- [ ] Configure Ollama settings (for Phi-3-mini model)

### 4. AI Model Setup (Ollama)
- [ ] Install Ollama (if not already installed)
- [ ] Pull Phi-3-mini model: `ollama pull phi3:mini`
- [ ] Verify Ollama service is running at http://localhost:11434

### 5. Frontend Setup
- [ ] Navigate to frontend/ directory
- [ ] Install Node.js dependencies: `npm install`
- [ ] Verify frontend configuration points to backend

### 6. Testing & Verification
- [ ] Test Neo4j connection: `python backend/test_neo4j_only.py`
- [ ] Test Ollama integration: `python backend/test_ollama.py`
- [ ] Test complete pipeline: `python backend/test_complete_pipeline.py`
- [ ] Start backend server: `uvicorn main:app --reload` (from backend/)
- [ ] Start frontend: `npm start` (from frontend/)
- [ ] Verify application runs at http://localhost:3000

### 7. Optional External Services (For Production)
- [ ] Azure Translator API (for multilingual support)
- [ ] Google Speech API (for voice input)

## Current Status
- âœ… Neo4j: Installed and configured
- âœ… Repository: Cloned
- âœ… Python Environment: Created and activated
- âœ… Database Setup: Neo4j configured with legal data
- âœ… Dependencies: All installed
- âœ… Backend: Running at http://localhost:8000
- âœ… Frontend: Running at http://localhost:3000
- âœ… System: Fully operational!

## Notes
- The project uses FastAPI for backend and React for frontend
- Neo4j password set to 'Avirup@190204'
- PostgreSQL setup was skipped (not required for core functionality)
- External services (Azure Translator, Google Speech) are optional and were skipped
- Using Ollama model: phi3:latest (instead of phi3:mini)

## Review

### Setup Completed Successfully! âœ…

**Date:** November 2, 2025

**What Was Accomplished:**

1. **Environment Setup**
   - Created Python virtual environment
   - Installed all Python dependencies (with Windows-compatible requirements)
   - Configured backend/.env file with correct credentials

2. **Database Configuration**
   - Neo4j Desktop configured and running
   - Created 'legalknowledge' database in Neo4j
   - Imported BNS Chapter XVII legal data (32 sections) into Neo4j knowledge graph
   - PostgreSQL setup skipped (not essential for core legal reasoning)

3. **AI Model Setup**
   - Ollama already installed
   - Using existing phi3:latest model (2.2 GB)
   - Updated .env to use phi3:latest instead of phi3:mini

4. **Neo4j Knowledge Graph Structure**
   - Created 1 Chapter node (Chapter XVII: Of Offences Against Property)
   - Created 32 Section nodes (BNS sections 303-332)
   - Created 32 Offence nodes with proper type mappings
   - Created 32 Punishment nodes linked by section_id
   - Established relationships: Chapter-[:CONTAINS]->Section-[:DEFINES]->Offence

5. **Testing Results**
   - âœ… Neo4j connection test: PASSED (4/4 tests)
   - âœ… Ollama integration test: PASSED (4/5 tests)
   - âœ… Complete pipeline test: PASSED (5/5 tests)
   - System successfully identifies: theft, dwelling theft, employee theft, robbery, snatching, extortion, trespass, and mischief

6. **Frontend Setup**
   - Installed npm dependencies (React, Material UI, Axios, Socket.IO)
   - Frontend running successfully at http://localhost:3000
   - Backend API integration confirmed (API calls returning 200 OK)

### Key Issues Resolved:

1. **Windows-specific package issues**
   - psycopg2-binary build errors â†’ Used >= version constraint
   - numpy compilation issues â†’ Used >= version constraint
   - pydantic Rust dependency â†’ Used newer version with prebuilt wheels
   - External service packages unavailable â†’ Commented out optional dependencies

2. **Neo4j data import challenges**
   - Initial import to wrong database â†’ Switched to 'legalknowledge' database
   - Graph structure alignment â†’ Matched exact schema expected by code
   - Property naming â†’ Ensured Section.text, Offence.type, Punishment.section_id match code queries

3. **Configuration adjustments**
   - Used phi3:latest instead of phi3:mini (already downloaded)
   - Set correct Neo4j password (Avirup@190204)
   - Skipped PostgreSQL (not critical for core functionality)

### System Architecture Now Running:

```
User Query â†’ Frontend (React + Material UI)
           â†“
Backend (FastAPI) â†’ Ollama (Phi-3-mini for entity extraction)
           â†“
Neo4j Knowledge Graph (BNS legal sections) â†’ Legal reasoning
           â†“
Response with applicable laws + punishment details
```

### Files Created/Modified:

1. `backend/.env` - Environment configuration
2. `requirements_windows.txt` - Windows-compatible dependencies
3. `verify_neo4j_data.py` - Data verification script
4. Neo4j legalknowledge database - Populated with BNS data

### Next Steps (Future Enhancements):

- Import remaining BNS chapters (if needed)
- Set up PostgreSQL for user session management (optional)
- Configure Azure Translator for multilingual support (optional)
- Configure Google Speech API for voice input (optional)
- Address frontend npm security vulnerabilities (low priority)
- Deploy to production environment

### Performance Notes:

- Entity extraction: ~2-3 seconds per query (Phi-3-mini via Ollama)
- Legal reasoning: <1 second (Neo4j graph queries)
- Property value estimation: <1 second
- End-to-end query processing: ~3-5 seconds

**Status: READY FOR USE! ðŸš€**

---

## LEGALS System Improvement Plan

**Based on:** NEXT_IMPROVEMENT_PLAN.md
**Date:** November 3, 2025
**Goal:** Enhance the system with better natural language understanding, graph-based reasoning, and improved response quality

### Current System Limitations:
- Relies on exact keyword matching ("stole" works, but "borrowed and never returned" fails)
- Legal logic hardcoded in Python (requires code changes for new patterns)
- Simple Neo4j graph structure (not using full graph reasoning capabilities)
- Template-based responses feel robotic
- Cannot explain WHY a law applies

### Improvement Phases Overview:

**Phase 1:** Enhanced BNS Knowledge Graph (Week 1-2)
**Phase 2:** Cypher Graph Rules (Week 3)
**Phase 3:** Semantic Similarity Layer (Week 4)
**Phase 4:** Hybrid Response Generator (Week 5)
**Phase 5:** Testing & Optimization (Week 6)

---

## PHASE 1: Enhanced BNS Knowledge Graph (Week 1-2)

### Objective:
Build a comprehensive legal knowledge graph with legal elements (mens rea, actus reus, circumstances) instead of simple section-offence-punishment structure.

### Tasks:

#### 1.1 Design Enhanced Graph Schema
- [ ] Create schema document for legal elements structure
- [ ] Define node types: Section, Offence, LegalElement (MensRea, ActusReus, Circumstance), ActionPattern, Punishment
- [ ] Define relationships: REQUIRES_MENS_REA, REQUIRES_ACTUS_REUS, REQUIRES_CIRCUMSTANCE, SATISFIES
- [ ] Document properties for each node type

#### 1.2 Create Graph Builder Script
- [ ] Create `backend/scripts/build_bns_knowledge_graph.py`
- [ ] Implement function to create Section nodes with enhanced properties
- [ ] Implement function to create LegalElement nodes (mens rea, actus reus, circumstance)
- [ ] Implement function to create ActionPattern nodes with variations
- [ ] Implement function to establish relationships between nodes

#### 1.3 Populate Graph for BNS Sections
- [ ] BNS-303: Theft (dishonest intent, taking property, without consent)
- [ ] BNS-304: Snatching (sudden taking, movable property)
- [ ] BNS-305: Dwelling house theft (theft + in dwelling)
- [ ] BNS-306: Employee theft (theft + position of trust)
- [ ] BNS-308: Extortion (obtaining property, by threat)
- [ ] BNS-309: Robbery (theft + violence/fear)
- [ ] BNS-316: Criminal breach of trust (entrusted property, dishonest misappropriation)
- [ ] BNS-318: Cheating (deception, inducing delivery of property)
- [ ] BNS-324: Mischief (damage property, intentional)
- [ ] BNS-329: Criminal trespass (entry, without permission, intent to commit offence)

#### 1.4 Create Action Pattern Library
- [ ] Theft patterns: "stole", "stolen", "took", "taken", "borrowed and never returned", "walked off with"
- [ ] Violence patterns: "threatened", "intimidated", "scared", "forced"
- [ ] Deception patterns: "cheated", "deceived", "tricked", "lied to obtain"
- [ ] Damage patterns: "damaged", "destroyed", "vandalized", "broke"
- [ ] Entry patterns: "entered", "trespassed", "broke in", "climbed over"

#### 1.5 Establish Section Relationships
- [ ] Create AGGRAVATED_FORM_OF relationships (e.g., BNS-305 is aggravated BNS-303)
- [ ] Create REQUIRES relationships between Offence and LegalElement nodes
- [ ] Add weights and mandatory flags to relationships

#### 1.6 Test Enhanced Graph
- [ ] Verify all nodes created correctly
- [ ] Verify all relationships established
- [ ] Test graph traversal queries
- [ ] Document graph statistics (node count, relationship count)

**Phase 1 Success Metrics:**
- Graph has 300+ nodes (sections, elements, patterns)
- Graph has 500+ relationships
- Can query via graph traversal (not Python code)

---

## PHASE 2: Replace Python Keyword Matching with Cypher Graph Rules (Week 3)

### Objective:
Replace all hardcoded Python if-else logic in `neo4j_service.py` with single Cypher graph query for legal reasoning.

### Tasks:

#### 2.1 Analyze Current Keyword Matching Logic
- [ ] Document all `_has_*_elements()` methods in neo4j_service.py
- [ ] Identify patterns in current logic
- [ ] Map current logic to graph query equivalents

#### 2.2 Design Universal Cypher Query
- [ ] Create Cypher query that matches user actions to ActionPatterns
- [ ] Query should find satisfied legal elements via graph traversal
- [ ] Calculate confidence based on matched vs required elements
- [ ] Return applicable sections with reasoning

#### 2.3 Rewrite neo4j_service.py
- [ ] Create new `find_applicable_laws_v2()` method using Cypher query
- [ ] Test new method against existing test cases
- [ ] Verify accuracy matches or exceeds current implementation
- [ ] Remove all `_has_*_elements()` methods once verified
- [ ] Update `find_applicable_laws()` to use new implementation

#### 2.4 Add Graph-Based Reasoning
- [ ] Include reasoning paths in query results
- [ ] Show which elements were matched and why
- [ ] Calculate confidence scores based on element matching

#### 2.5 Testing
- [ ] Run all existing test files to ensure no regression
- [ ] Test with natural language variations
- [ ] Verify performance (should be faster than Python loops)

**Phase 2 Success Metrics:**
- Delete all `_has_*_elements()` methods (200+ lines removed)
- Replace with single graph query method
- Same or better accuracy
- Explainable reasoning (graph paths show why)

---

## PHASE 3: Add Semantic Similarity Layer (Week 4)

### Objective:
Enable understanding of natural language variations using semantic similarity (e.g., "borrowed and never returned" = "misappropriated").

### Tasks:

#### 3.1 Setup Dependencies
- [ ] Add sentence-transformers to requirements.txt
- [ ] Add torch to requirements.txt
- [ ] Add numpy to requirements.txt
- [ ] Install dependencies in virtual environment

#### 3.2 Create Semantic Enhancement Service
- [ ] Create `backend/app/services/semantic_enhancement_service.py`
- [ ] Load sentence-transformers model (all-MiniLM-L6-v2)
- [ ] Implement embedding cache for performance
- [ ] Pre-compute embeddings for legal action terms

#### 3.3 Implement Action Enhancement
- [ ] Create `enhance_actions()` method to map user actions to legal terms
- [ ] Use cosine similarity to find semantically similar legal actions
- [ ] Set confidence threshold (>0.75) for matches
- [ ] Return enhanced actions with confidence scores

#### 3.4 Build Legal Action Dictionary
- [ ] Define theft-related actions with descriptions
- [ ] Define fraud-related actions with descriptions
- [ ] Define violence-related actions with descriptions
- [ ] Define property damage actions with descriptions
- [ ] Define trespass actions with descriptions

#### 3.5 Integrate with Entity Extraction
- [ ] Modify `ollama_service.py` to use semantic enhancement
- [ ] Add semantic_enhancer initialization
- [ ] Update `extract_entities()` to enhance actions
- [ ] Include both original and enhanced actions in results

#### 3.6 Testing
- [ ] Test with "borrowed and never returned" â†’ should map to "misappropriated"
- [ ] Test with "took money from company account" â†’ should map to "embezzled"
- [ ] Test with "scared into giving money" â†’ should map to "extorted"
- [ ] Measure latency increase (should be <100ms)

**Phase 3 Success Metrics:**
- Natural language success rate: 50% â†’ 80%+
- Latency increase: <100ms
- "borrowed never returned" correctly maps to legal term

---

## PHASE 4: Hybrid Response Generator with Mistral-7B (Week 5)

### Objective:
Generate natural, personalized responses while maintaining deterministic core and preventing hallucinations.

### Tasks:

#### 4.1 Install Mistral-7B Model
- [ ] Run `ollama pull mistral:7b-instruct`
- [ ] Verify model is available in Ollama
- [ ] Test basic inference with Mistral

#### 4.2 Create Hybrid Response Generator Service
- [ ] Create `backend/app/services/hybrid_response_generator.py`
- [ ] Implement `generate_response()` main method
- [ ] Implement `_build_structured_content()` for deterministic core
- [ ] Implement `_enhance_with_mistral()` for LLM enhancement

#### 4.3 Build Structured Content Components
- [ ] Create applicable sections formatter
- [ ] Create case summary builder
- [ ] Create property analysis formatter
- [ ] Create immediate actions generator (deterministic, crime-specific)
- [ ] Create legal rights formatter
- [ ] Create punishments formatter
- [ ] Always include disclaimers

#### 4.4 Implement LLM Enhancement
- [ ] Design prompt template for Mistral
- [ ] Ensure prompt includes all verified legal info
- [ ] Add strict constraints (no additions, no changes to legal conclusions)
- [ ] Call Mistral with temperature=0.3 for consistency

#### 4.5 Create Validation Layer
- [ ] Validate all required sections are mentioned
- [ ] Validate disclaimers are present
- [ ] Validate no hallucinated sections (check for BNS numbers not in input)
- [ ] Validate response length is reasonable
- [ ] Implement fallback to template if validation fails

#### 4.6 Integrate with Legal Processing Service
- [ ] Modify `legal_processing_service.py` to use new generator
- [ ] Replace old response generation with hybrid approach
- [ ] Ensure backward compatibility

#### 4.7 Testing
- [ ] Test response naturalness (should feel more conversational)
- [ ] Test personalization (should mention user's specific items/location)
- [ ] Test validation (intentionally provide bad input, verify fallback works)
- [ ] Measure response time (should be 10-15 seconds)
- [ ] Verify no legal hallucinations in 100 test queries

**Phase 4 Success Metrics:**
- Response quality: More natural, less robotic
- Personalization: Mentions user's specific situation
- Validation pass rate: >95% (hallucinations caught)
- Fallback rate: <5%
- Response time: 10-15 seconds

---

## PHASE 5: Testing & Optimization (Week 6)

### Objective:
Comprehensive testing, performance optimization, and documentation of improvements.

### Tasks:

#### 5.1 Create Comprehensive Test Suite
- [ ] Create `backend/tests/test_natural_language_queries.py`
- [ ] Create `backend/tests/test_graph_reasoning.py`
- [ ] Create `backend/tests/test_response_quality.py`
- [ ] Create `backend/tests/test_semantic_similarity.py`

#### 5.2 Test Natural Language Variations
- [ ] Test 20+ theft variations (stole, took, borrowed never returned, etc.)
- [ ] Test 10+ breach of trust variations
- [ ] Test 10+ fraud/cheating variations
- [ ] Test 10+ extortion variations
- [ ] Test 10+ property damage variations
- [ ] Test 10+ trespass variations
- [ ] Test 20+ complex multi-offense scenarios
- [ ] Document success rate for each category

#### 5.3 Performance Optimization
- [ ] Create embedding cache for common phrases
- [ ] Add Neo4j indexes on section_number, element_type, action_pattern
- [ ] Implement response caching for identical queries (1-hour TTL)
- [ ] Optimize Cypher query performance
- [ ] Profile bottlenecks and optimize

#### 5.4 Measure Performance Benchmarks
- [ ] Measure end-to-end response time (target: <15 seconds)
- [ ] Measure graph query time (target: <200ms)
- [ ] Measure semantic enhancement time (target: <100ms)
- [ ] Measure LLM response time (target: <10 seconds)
- [ ] Document results in performance report

#### 5.5 Accuracy Testing
- [ ] Test with 100+ query variations
- [ ] Measure natural language accuracy (target: >80%)
- [ ] Measure false positive rate (target: <10%)
- [ ] Test edge cases and boundary conditions
- [ ] Document accuracy improvements

#### 5.6 Documentation
- [ ] Document new graph schema in README
- [ ] Create API documentation for new endpoints
- [ ] Update system architecture diagram
- [ ] Document semantic similarity approach
- [ ] Create troubleshooting guide

**Phase 5 Success Metrics:**
- 100+ queries tested with >80% accuracy
- End-to-end response time <15 seconds
- False positive rate <10%
- All tests pass with no regressions

---

## Implementation Order

**Week 1-2:** Phase 1 - Enhanced Knowledge Graph
**Week 3:** Phase 2 - Cypher Graph Rules
**Week 4:** Phase 3 - Semantic Similarity
**Week 5:** Phase 4 - Hybrid Response Generator
**Week 6:** Phase 5 - Testing & Optimization

---

## Expected Improvements After Completion

### Accuracy:
- Exact keywords: 90% â†’ 95% (+5%)
- Natural language: 50% â†’ 85% (+35%)
- Complex scenarios: 30% â†’ 75% (+45%)
- **Overall: 60% â†’ 85% (+25%)**

### User Experience:
- Response quality: Template-based â†’ Natural, personalized
- Explanation depth: Basic â†’ Detailed with reasoning
- Confidence: Moderate â†’ High (explainable)
- Actionability: Good â†’ Excellent

### System Characteristics:
- Deterministic: Yes (structured core + validation)
- Explainable: Yes (graph paths show reasoning)
- Scalable: Yes (add sections via graph, not code)
- Maintainable: Yes (data-driven, not code-driven)
- Multilingual: Yes (English + Hindi via Mistral)
- Fast: Yes (10-15 seconds end-to-end)

---

## Files to Create

### Phase 1:
- `backend/scripts/build_bns_knowledge_graph.py`
- `backend/data/bns_knowledge_graph_schema.json`

### Phase 3:
- `backend/app/services/semantic_enhancement_service.py`

### Phase 4:
- `backend/app/services/hybrid_response_generator.py`

### Phase 5:
- `backend/tests/test_natural_language_queries.py`
- `backend/tests/test_graph_reasoning.py`
- `backend/tests/test_response_quality.py`
- `backend/tests/test_semantic_similarity.py`

## Files to Modify

### Phase 2:
- `backend/app/services/neo4j_service.py` (major rewrite - replace keyword matching)

### Phase 3:
- `backend/app/services/ollama_service.py` (add semantic enhancement)
- `requirements.txt` (add new dependencies)

### Phase 4:
- `backend/app/services/legal_processing_service.py` (use hybrid response generator)

---

## Notes

### Why This Approach:
1. **Incremental:** Each phase builds on previous work
2. **Simple:** Focus on one improvement at a time
3. **Testable:** Can verify each phase independently
4. **Safe:** Maintains deterministic core, prevents hallucinations
5. **Scalable:** Data-driven (graph) instead of code-driven

### Key Principles:
- Keep changes simple and modular
- Test after each phase
- Maintain backward compatibility
- Never compromise on deterministic reasoning
- Always include legal disclaimers

---

## Review Section
(To be filled after implementation)
